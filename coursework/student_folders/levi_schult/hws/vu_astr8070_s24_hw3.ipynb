{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASTR 8070: Astrostatistics\n",
    "***S. R. Taylor***\n",
    "___\n",
    "\n",
    "# Homework 3\n",
    "### Due: Saturday, Feb 10th at 11.59pm CST\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only one problem this week\n",
    "\n",
    "This problem uses a dataset in `/coursework/homeworks/hw_data/`.\n",
    "\n",
    "1) Read in `hw3_data_1.npy`. This is a (50 x 2) numpy array, with measurements in the first column and uncertainties in the second column. Using the analytic results for heteroscedastic Gaussian data from lectures, compute the sample mean and the standard error on the sample mean from for this data.\n",
    "\n",
    "2) Reusing some approaches and tools from `Lecture_6`, write a ln-likelihood function for heteroscedastic Gaussian data, and use it in a fitting algorithm to find the best-fit mean. *Remember that scipy optimizers are set up to minimize functions.*\n",
    "\n",
    "3) Using the same numerical technique from `Lecture_5`, compute the Fisher uncertainty estimate on the mean.\n",
    "\n",
    "4) Using the bootstrap method, generate $1000$ bootstrap realizations of this dataset. *DO NOT use the `astroML` code. Write your own bootstrap function from scratch. Also recall that when resampling data, measurements and uncertainties should stay paired together.*\n",
    "\n",
    "5) Repeat (2) with all $1000$ boostrap datasets to find the distribution of the sample mean. Plot a normalized histogram of these bootstrap means, and overplot a Gaussian pdf with the mean and std found in (1). Do these agree?\n",
    "\n",
    "6) While we have fitted a heteroscedastic Gaussian to this data, let's try something else. Write some code to define a ln-likelihood for a Laplace distribution evaluated on this data. Fit simultaneously for the Laplace location parameter $\\mu$ and scale parameter $\\Delta$.\n",
    "\n",
    "7) Compute the AIC values for the heteroscedastic Gaussian model and the Laplacian model. Which model is favored by the data?\n",
    "\n",
    "8) Using the $1000$ bootstrap datasets from before, fit for the Laplacian $\\mu$ and $\\Delta$ for each. Make a nice `corner` plot of the distributions of $\\mu$ and $\\Delta$ that shows both the marginal $1$D distributions and the joint $2$D distribution. Make sure the plot has labels, shows the titles on each $1$D marginal panel, and has $68\\%$ and $95\\%$ levels.\n",
    "\n",
    "9) Let's finish with a Fisher uncertainty estimate of the Laplacian parameters. Use the following code to install `numdifftools` which provides a simple way to compute derivatives. We can then compute the Hessian matrix, which is the matrix of the second derivatives of the user's function. This should be computed at the best-fit Laplacian parameters $\\mu$ and $\\Delta$. To finish, invert the matrix, and then take the square root. The diagonal entries will then be the Fisher uncertainties on $\\mu$ and $\\Delta$. How does these compare to the bootstrap distribution widths found in (8)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numdifftools\n",
      "  Downloading numdifftools-0.9.41-py2.py3-none-any.whl (100 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.2/100.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9 in /Users/levischult/miniconda3/envs/astr8070/lib/python3.10/site-packages (from numdifftools) (1.26.3)\n",
      "Requirement already satisfied: scipy>=0.8 in /Users/levischult/miniconda3/envs/astr8070/lib/python3.10/site-packages (from numdifftools) (1.11.4)\n",
      "Installing collected packages: numdifftools\n",
      "Successfully installed numdifftools-0.9.41\n"
     ]
    }
   ],
   "source": [
    "!pip install numdifftools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numdifftools as nd\n",
    "import numpy as np \n",
    "import scipy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For later:\n",
    "# H = nd.Hessian(f_lnlaplace)([beta_laplace[0], beta_laplace[1]])\n",
    "# sigma_laplace = np.linalg.inv(H)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('../../../homeworks/hw_data/hw3_data_1.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat \\mu = \\frac{\\sum_i^N (x_i/\\sigma_i^2)}{\\sum_i^N (1/\\sigma_i^2)},$$\n",
    "\n",
    "with uncertainty\n",
    "$$\\sigma_{\\mu} = \\left( \\sum_{i=1}^N \\frac{1}{\\sigma_i^2}\\right)^{-1/2}.$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def het_mean_sigma_analytic(data):\n",
    "    '''\n",
    "    data (ndarray): N measurements x 2 array where [:, 1] are the uncertainties\n",
    "\n",
    "    returns:\n",
    "    mean (float): mean analytically calculated for heteroscedastic data\n",
    "    sigmu (float): uncertainty on the mean analytically calc.\n",
    "    '''\n",
    "    numerator = np.sum(data[:, 0] / data[:, 1]**2) # LSS sum of measurement over\n",
    "    # the square of the respective uncertainties\n",
    "    denom = np.sum(data[:, 1]**-2) # LSS sum of the inverse square of the uncert.\n",
    "\n",
    "    mean = numerator / denom\n",
    "\n",
    "    sigmu = denom**-0.5 # LSS uncert on mean is denominator to the -0.5\n",
    "    return mean, sigmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamean_an, datasigmu_an = het_mean_sigma_analytic(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analytically calculated mu=3.92, sigma_mu=0.09\n"
     ]
    }
   ],
   "source": [
    "print(f'analytically calculated mu={datamean_an:.2f}, sigma_mu={datasigmu_an:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
